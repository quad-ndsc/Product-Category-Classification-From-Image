{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from math import ceil\n",
    "\n",
    "from smallervggnet import SmallerVGGNet\n",
    "\n",
    "EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 128\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    "\n",
    "def train(dataset_path):\n",
    "    # initialize the number of epochs to train for, initial learning rate,\n",
    "    # batch size, and image dimensions\n",
    "\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    \n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    \n",
    "    dataset = dataset[dataset\n",
    "                          .image_path\n",
    "                          .apply(lambda image_path: image_path.startswith('mobile_image'))]\n",
    "    \n",
    "    dataset = dataset.head(int(len(dataset)/1))\n",
    "    dataset.Category = dataset.Category.apply(str)\n",
    "    \n",
    "    unique_categories = dataset['Category'].unique().tolist()\n",
    "    \n",
    "    # binarize the labels using scikit-learn's special multi-label\n",
    "    # binarizer implementation\n",
    "    print(\"[INFO] class labels: \" + str(unique_categories))\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(unique_categories)\n",
    "\n",
    "    trainset, testset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # construct the image generator for data augmentation\n",
    "    image_data_gen = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "        horizontal_flip=True, fill_mode=\"nearest\", rescale=1/255.0, dtype=float)\n",
    "    \n",
    "    trainset_iter = image_data_gen.flow_from_dataframe(trainset,\n",
    "                                                        directory='./',\n",
    "                                                        x_col='image_path',\n",
    "                                                        y_col='Category',\n",
    "                                                        target_size=(IMAGE_DIMS[1], IMAGE_DIMS[0]),\n",
    "                                                        color_mode='rgb',\n",
    "                                                        class_mode='categorical',\n",
    "                                                        classes=unique_categories,\n",
    "                                                        batch_size=BS)\n",
    "    \n",
    "    testset_iter = image_data_gen.flow_from_dataframe(testset,\n",
    "                                                    directory='./',\n",
    "                                                    x_col='image_path',\n",
    "                                                    y_col='Category',\n",
    "                                                    target_size=(IMAGE_DIMS[1], IMAGE_DIMS[0]),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                    classes=unique_categories,\n",
    "                                                    batch_size=BS)\n",
    "    \n",
    "    # initialize the model using a sigmoid activation as the final layer\n",
    "    # in the network so we can perform multi-label classification\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model = SmallerVGGNet.build(\n",
    "        width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "        depth=IMAGE_DIMS[2], classes=len(unique_categories),\n",
    "        finalAct=\"softmax\")\n",
    "    # initialize the optimizer\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    \n",
    "    # compile the model using binary cross-entropy rather than\n",
    "    # categorical cross-entropy -- this may seem counterintuitive for\n",
    "    # multi-label classification, but keep in mind that the goal here\n",
    "    # is to treat each output label as an independent Bernoulli\n",
    "    # distribution\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    # checkpoint\n",
    "    filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.model\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit_generator(\n",
    "        trainset_iter,\n",
    "        validation_data=testset_iter,\n",
    "        steps_per_epoch=ceil(len(trainset) / BS),\n",
    "        validation_steps=ceil(len(testset) / BS),\n",
    "        epochs=EPOCHS, verbose=1, use_multiprocessing=True, callbacks=callbacks_list)\n",
    "    \n",
    "    return (model, lb, H)\n",
    "\n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the arguments, if using a notebook then edit in `else`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "if not is_interactive():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "        help=\"path to train.csv\")\n",
    "    ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "        help=\"path to output model\")\n",
    "    ap.add_argument(\"-l\", \"--labelbin\", required=True,\n",
    "        help=\"path to output label binarizer\")\n",
    "    ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "        help=\"path to output accuracy/loss plot\")\n",
    "    args = vars(ap.parse_args())\n",
    "else:\n",
    "    args = {}\n",
    "    args['dataset'] = '../train.csv'\n",
    "    args['model'] = 'mobile_categorizer.model'\n",
    "    args['labelbin'] = 'lb.pickle'\n",
    "    args[\"plot\"] = 'plot.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] class labels: ['31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57']\n",
      "Found 128264 images belonging to 27 classes.\n",
      "Found 32066 images belonging to 27 classes.\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:From /c/Users/YesYouKen/Desktop/Product-Category-Classification-From-Image/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "  19/1003 [..............................] - ETA: 2:24:48 - loss: 0.2053 - acc: 0.9574"
     ]
    }
   ],
   "source": [
    "model, lb, H = train(args['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(args[\"model\"])\n",
    "\n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(args[\"labelbin\"], \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
